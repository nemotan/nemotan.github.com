---
layout: post
title: hive【八】hive实现增量分析
categories: 
- hive
tags: 
- hive
---
[toc]

## hive增量分析
**背景：**每天上传到服务器的日志，经过**每日增量分析**得到当天的结果，然后合并更新到总结果集。并且只把更新的数据导入到mongodb结果数据库。


```java
sh portal\_use file\_month day 2015-09-07
```
1、初始化创建一个结果集表res\_portal\_use，以用户ID和维度分区。LAST\_UPDATE表示该行数据**最后更新时间**。

	CREATE TABLE IF NOT EXISTS RES_PORTAL_USE(  
	FDID STRING,  
	COUNT BIGINT,  
	LAST_UPDATE DATE  
	）  
	PARTITIONED BY (ID STRING,SCOP STRING)  
	ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';  
	2、当天的结果表：tmp\_portal\_use\_20151104,其中LAST\_UPDAYET为今天的日期。对flume上传到hdfs上的今天的日志进行分析，得出今天的结果集。

3、两个表中的字段是一样的，union all之后进行sum(count),max(LAST\_UPDATE)就是增量之和以及LAST\_UPDATE为今天的是要导入到mongodb的结果集。该结果集放到tmp\_portal\_use表中

	INSERT OVERWRITE TABLE TMP_RES_portal_use PARTITION(ID,SCOP) SELECT sub.FDID AS FDID,SUM(sub.COUNT) AS COUNT,MAX(sub.LAST_UPDATE) AS LAST_UPDATE,sub.ID as ID,sub.SCOP as SCOP FROM (SELECT fdid,count,to_date('2015-11-05') as LAST_UPDATE,id,scop FROM tmp_portal_use_20151105 UNION ALL SELECT * FROM RES_portal_use)sub GROUP BY sub.ID,sub.SCOP,sub.FDID  
> 注意：该处需要用到动态分区。

4、导入之后，先删除旧的res\_portal\_use表，再把tmp\_portal\_use表重命名为res\_portal\_use表。那么res\_portal\_use就变成了最新的结果集表。

 
 ```ava
 28 #移除old结果集  
 29 hive -e "DROP TABLE tmp_$0_${\_date}"  
 30 hive -e "DROP TABLE RES_$0"  
 31 #重命名新结果集  
 32 hive -e "ALTER TABLE TMP\_RES_$0 RENAME TO RES\_$0"  
 33 #导入更新的结果  
 ```
5、把res\_portal\_use表中LAST\_UPDATE为今天的的数据更新导入到mongodb中。

## hive性能分析
### 构建数据脚本

```java
# !/bin/bash
if [ $# -ne 1 ]
   then
	echo "请输入一个参数"
	return
fi
FILE\_NAME="$1.txt"

if [ ! -f $FILE\_NAME ]
   then
	    echo "创建$FILE_NAME数据"
	    `sh build.sh $1 $FILE_NAME`
	    echo "创建完成"
fi

echo "$FILE\_NAME已经存在!直接运行计算......"
echo "第一步，清理原始数据......"
`hadoop fs -rmr /output/logs/request_transform/2015-11/2015-11-10/*`
echo "第一步，清理完成"
echo "第二步，清理上次结果表,并创建新表和分区。。。。。。"
hive -e 'drop table res\_portal\_use'
hive -f ../create\_table.sql
`ALTER TABLE request_log ADD PARTITION(month='2015-11',day='2015-11-10') LOCATION '/output/logs/request_transform/2015-11/2015-11-10'`
echo "第二步，重建表完成！"

echo "第三步，上传文件到hive......"
`hadoop fs -copyFromLocal ./$FILE_NAME /output/logs/request_transform/2015-11/2015-11-10`
echo "第三步，上传完成"

echo "第四步，执行分析......"
sh ../request/portal\_use file\_month day 2015-11-10
```

### 遇到的问题
#### 问题一：测试数据大的时候后，job一致处于appending状态

```java
利用jps查看，发现nodemanager都被干掉了，于是先stop-yan.sh然后start-yarn.sh重启。
```

#### 问题二:内存不够的问题

```java
因为hadoop默认每个map任务和reduce任务默认的内存分配是1024，所以当分配的总内存算机的内存的时候则会出现问题。  

解决办法：修改mappred-site.xml,yarn-site.xml相关配置
mapreduce.map.memory.mb  
mapreduce.reduce.memory.mb
set mapreduce.input.fileinputformat.split.maxsize=1024000;  
set yarn.timeline-service.handler-thread-count=2;
```

#### 问题三：如何控制map个数

==设置分片大小==

```java
mapreduce.input.fileinputformat.split.minsize  #默认为1  
mapreduce.input.fileinputformat.split.maxsize  #默认为256M  
dfs.block.size #块大小
# 计算分片大小的公式
  protected long computeSplitSize(long blockSize, long minSize,
	                              long maxSize) {
	return Math.max(minSize, Math.min(maxSize, blockSize));
  }
  
  
在hadoop中blocksize：128M，为什么hive中map数目以256M为一个split进行分割呢？
因为：参数：set mapred.max.split.size = 256000000 ; //最大分割
该参数是hive进行map端分割的参数

```
## mongodb性能分析
## 分析结果

|条数(万条)|大小|M-R：耗时(S)|总耗时(S)||mongodb耗时(S)|
|---|---|---|--|--|--|
|50|242|2-1:16|120|
|100|484|2-1:38|168|
|100|484|4-1:34|156|
|500|2418|4-1:65|176|
|1000|4836|4-1:86|206|

## 附录
### 用到的linux命令

```java
# head -n 10000 log.txt \>\> 1W.tx        #取W条记录
# more 1W.txt | wc -l                   #计数
# du -h                                 #查看文件大小
# du -m --max-depth=1  /etc | sort -nr  #查看文件夹大小
# du --max-depth=1 -h                   #当前目录
# ls -l --block-size=M                  #查看文件大小
```
### 用到的hadoop相关命令


```java
$ hadoop fs -ls /output/logs/request\_transform         #查询  
$ hadoop fs -mkdir /output/logs/request\_transform/2015-09/2015-09-08 #创建一个目录  
$ hadoop fs -copyFromLocal ./100W.txt /output/logs/request\_transform/2015-09/2015-09-08        #上传到hdfs  
$ hadoop fs -copyToLocal       #下载到本地  
$ hadoop fs -rmr /output/logs/request\_transform/2015-09/2015-09-08  
$ mapred job -list             #显示当前的job  
$ mapred job -kill jobid        #killjiob
```
